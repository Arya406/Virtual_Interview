{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559833c9-de10-48c4-ace5-bd75620235e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\gupta\\anaconda3\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\gupta\\anaconda3\\lib\\site-packages (0.3.51)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\gupta\\anaconda3\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: groq in c:\\users\\gupta\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Collecting pypdf2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-docx in c:\\users\\gupta\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from groq) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 122.9/232.6 kB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 225.3/232.6 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf2\n",
      "Successfully installed pypdf2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-core langchain-community groq pypdf2 python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e672e39-e9f7-4d26-b0a0-903f4ae27de9",
   "metadata": {},
   "source": [
    "## Set Up LangChain with Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708f410c-5dfa-4e94-b471-7f0e8d3e1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.environ[\"GROQ_API_KEY\"],\n",
    "    model_name=\"llama-3.3-70b-versatile\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8e274-6521-4658-8c40-654a94b428d6",
   "metadata": {},
   "source": [
    "## PDF & DOCX Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4083bab5-087c-495f-b9fa-0bfc35ee82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    from PyPDF2 import PdfReader\n",
    "    reader = PdfReader(file_path)\n",
    "    return \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    from docx import Document\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecf04c-d7bb-4296-bf22-d09fae851229",
   "metadata": {},
   "source": [
    "## LangChain Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2897d89-43ac-4525-8bbc-f0eb685396e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent resume parser.\n",
    "\n",
    "Extract these fields from the resume text:\n",
    "- skills: List of programming languages, tools, technologies.\n",
    "- experience: List of roles with job_title, company, duration, description.\n",
    "- projects: List of projects with title, description, and link (if any).\n",
    "\n",
    "Resume Text:\n",
    "```{text}```\n",
    "\n",
    "Respond ONLY in this JSON format:\n",
    "{{\n",
    "  \"skills\": [...],\n",
    "  \"experience\": [\n",
    "    {{\n",
    "      \"job_title\": \"...\",\n",
    "      \"company\": \"...\",\n",
    "      \"duration\": \"...\",\n",
    "      \"description\": \"...\"\n",
    "    }}\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    {{\n",
    "      \"title\": \"...\",\n",
    "      \"description\": \"...\",\n",
    "      \"link\": \"...\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f92954-9195-4807-8589-326812d84aaa",
   "metadata": {},
   "source": [
    "## Run LangChain Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070c4c76-df47-4001-b089-ec68ec60bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter resume path (.pdf/.docx):  D:\\\\OneDrive\\\\Desktop\\\\AbhinavGuptaResume2025.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM Response:\n",
      " content='```\\n{\\n  \"skills\": [\\n    \"C\",\\n    \"Java\",\\n    \"C++\",\\n    \"Python\",\\n    \"TypeScript\",\\n    \"React.js\",\\n    \"Next.js\",\\n    \"React Native\",\\n    \"Node.js\",\\n    \"Express.js\",\\n    \"Django\",\\n    \"Flask\",\\n    \"MySQL\",\\n    \"MongoDB\",\\n    \"Git/GitHub\",\\n    \"Vercel\",\\n    \"Render\",\\n    \"AppWrite\",\\n    \"Cloudinary\",\\n    \"Postman\",\\n    \"Firebase\",\\n    \"Pandas\",\\n    \"NumPy\",\\n    \"Scikit-learn\",\\n    \"OpenCV\",\\n    \"TensorFlow\",\\n    \"Keras\",\\n    \"PyTorch\",\\n    \"Seaborn\",\\n    \"Matplotlib\",\\n    \"SpaCy\",\\n    \"NLTK\"\\n  ],\\n  \"experience\": [\\n    {\\n      \"job_title\": \"Full Stack Developer Intern\",\\n      \"company\": \"Nextup Robotics Pvt. Ltd\",\\n      \"duration\": \"Dec 2024 - Feb 2025\",\\n      \"description\": \"Developed a React.js-based control interface integrated with ROS 2 Humble for real-time robot communication. Implemented REST APIs WebSockets for seamless robot commands and telemetry data visualization.\"\\n    },\\n    {\\n      \"job_title\": \"Frontend Developer Intern\",\\n      \"company\": \"Abhiwan Technology Pvt. Ltd\",\\n      \"duration\": \"Jan 2024 - Apr 2024\",\\n      \"description\": \"Built responsive web interfaces with React.js, ensuring smooth UX and accessibility. Converted Figma wireframes into interactive components and integrated REST APIs.\"\\n    }\\n  ],\\n  \"projects\": [\\n    {\\n      \"title\": \"CODE-CAP\",\\n      \"description\": \"Built a platform for students to form hackathon teams using filters (year, gender, college, branch). Optimized search filters and provided real-time hackathon updates.\",\\n      \"link\": \"Live Link\"\\n    },\\n    {\\n      \"title\": \"SOCRATES\",\\n      \"description\": \"Created an AI-powered learning platform with a Socratic teaching approach for CSE fundamentals. Integrated an interactive code compiler, a scribble pad, and a LeetCode extension with strategic hints.\",\\n      \"link\": \"YouTube Link\"\\n    },\\n    {\\n      \"title\": \"MedXpertAI\",\\n      \"description\": \"Developed an AI-powered disease prediction system based on user-selected symptoms. Provided personalized precautions, diet plans, and workout recommendations.\",\\n      \"link\": \"YouTube Link\"\\n    }\\n  ]\\n}\\n```' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 521, 'prompt_tokens': 781, 'total_tokens': 1302, 'completion_time': 1.894545455, 'prompt_time': 0.057556522, 'queue_time': 0.054393207, 'total_time': 1.9521019769999999}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None} id='run-20680e1f-9c86-4f17-bef7-1ce401e230ac-0' usage_metadata={'input_tokens': 781, 'output_tokens': 521, 'total_tokens': 1302}\n"
     ]
    }
   ],
   "source": [
    "# Resume path\n",
    "resume_path = input(\"Enter resume path (.pdf/.docx): \")\n",
    "\n",
    "if resume_path.endswith(\".pdf\"):\n",
    "    resume_text = extract_text_from_pdf(resume_path)\n",
    "elif resume_path.endswith(\".docx\"):\n",
    "    resume_text = extract_text_from_docx(resume_path)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "# Use the new RunnableSequence format\n",
    "chain = prompt | llm\n",
    "\n",
    "# Invoke the chain\n",
    "response = chain.invoke({\"text\": resume_text})\n",
    "\n",
    "# Optional: If JSON output expected\n",
    "import json\n",
    "try:\n",
    "    parsed_data = json.loads(response.content if hasattr(response, 'content') else response)\n",
    "    print(\"Parsed Data:\", parsed_data)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Raw LLM Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627150b7-d691-4cc1-b078-f6b60b7b06e7",
   "metadata": {},
   "source": [
    "## Parse JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10019d2d-bd80-4f4e-9c4a-9c521c973dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Skills:\n",
      "C\n",
      "Java\n",
      "C++\n",
      "Python\n",
      "TypeScript\n",
      "React.js\n",
      "Next.js\n",
      "React Native\n",
      "Node.js\n",
      "Express.js\n",
      "Django\n",
      "Flask\n",
      "MySQL\n",
      "MongoDB\n",
      "Git/GitHub\n",
      "Vercel\n",
      "Render\n",
      "AppWrite\n",
      "Cloudinary\n",
      "Postman\n",
      "Firebase\n",
      "Pandas\n",
      "NumPy\n",
      "Scikit-learn\n",
      "OpenCV\n",
      "TensorFlow\n",
      "Keras\n",
      "PyTorch\n",
      "Seaborn\n",
      "Matplotlib\n",
      "SpaCy\n",
      "NLTK\n",
      "\n",
      "💼 Experience:\n",
      "Full Stack Developer Intern at Nextup Robotics Pvt. Ltd (Dec 2024 - Feb 2025)\n",
      "Developed a React.js-based control interface integrated with ROS 2 Humble for real-time robot communication. Implemented REST APIs WebSockets for seamless robot commands and telemetry data visualization.\n",
      "\n",
      "Frontend Developer Intern at Abhiwan Technology Pvt. Ltd (Jan 2024 - Apr 2024)\n",
      "Built responsive web interfaces with React.js, ensuring smooth UX and accessibility. Converted Figma wireframes into interactive components and integrated REST APIs.\n",
      "\n",
      "\n",
      "🚀 Projects:\n",
      "CODE-CAP - Built a platform for students to form hackathon teams using filters (year, gender, college, branch). Optimized search filters and provided real-time hackathon updates.\n",
      "Link: Live Link\n",
      "\n",
      "SOCRATES - Created an AI-powered learning platform with a Socratic teaching approach for CSE fundamentals. Integrated an interactive code compiler, a scribble pad, and a LeetCode extension with strategic hints.\n",
      "Link: YouTube Link\n",
      "\n",
      "MedXpertAI - Developed an AI-powered disease prediction system based on user-selected symptoms. Provided personalized precautions, diet plans, and workout recommendations.\n",
      "Link: YouTube Link\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "try:\n",
    "    \n",
    "    raw = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "    \n",
    "    json_match = re.search(r'\\{.*\\}', raw, re.DOTALL)\n",
    "    if not json_match:\n",
    "        raise ValueError(\"No JSON object found in the response.\")\n",
    "    \n",
    "    json_str = json_match.group()\n",
    "\n",
    "    \n",
    "    parsed_data = json.loads(json_str)\n",
    "\n",
    "   \n",
    "    skills = parsed_data.get(\"skills\", [])\n",
    "    experience = parsed_data.get(\"experience\", [])\n",
    "    projects = parsed_data.get(\"projects\", [])\n",
    "\n",
    "    \n",
    "    print(\"\\n🔧 Skills:\")\n",
    "    print(\"\\n\".join(skills))\n",
    "\n",
    "    print(\"\\n💼 Experience:\")\n",
    "    for exp in experience:\n",
    "        print(f\"{exp.get('job_title', '')} at {exp.get('company', '')} ({exp.get('duration', '')})\")\n",
    "        print(f\"{exp.get('description', '')}\\n\")\n",
    "\n",
    "    print(\"\\n🚀 Projects:\")\n",
    "    for proj in projects:\n",
    "        print(f\"{proj.get('title', '')} - {proj.get('description', '')}\")\n",
    "        print(f\"Link: {proj.get('link', 'N/A')}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ LLM response was not valid JSON. Here's the raw output:\\n\")\n",
    "    print(raw)\n",
    "    print(\"\\nError:\", e)\n",
    "\n",
    "\n",
    "print(type(raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d423785-d481-4147-97bb-f3f4cef23b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
